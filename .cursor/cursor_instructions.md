# Instructions Cursor - Projet d'Analyse de Corr√©lations Crypto

## üéØ OBJECTIF DU PROJET

D√©velopper une strat√©gie de trading bas√©e sur l'analyse scientifique des corr√©lations entre 6 paires de cryptomonnaies, en utilisant des m√©thodes d'√©conom√©trie financi√®re avanc√©es, avec pour but final la cr√©ation d'indicateurs rentables et leur impl√©mentation sur TradingView.

---

## üìä PAIRES ANALYS√âES

- BTCUSDT
- ETHUSDT
- XRPUSDT
- SOLUSDT
- DOGEUSDT
- BNBUSDT

---

## üóÇÔ∏è STRUCTURE DU PROJET

```
project_root/
‚îú‚îÄ‚îÄ data/                          # Fichiers Excel (timeframe 1H, 3 mois, avec CVD)
‚îÇ   ‚îú‚îÄ‚îÄ BTCUSDT.xlsx
‚îÇ   ‚îú‚îÄ‚îÄ ETHUSDT.xlsx
‚îÇ   ‚îú‚îÄ‚îÄ XRPUSDT.xlsx
‚îÇ   ‚îú‚îÄ‚îÄ SOLUSDT.xlsx
‚îÇ   ‚îú‚îÄ‚îÄ DOGEUSDT.xlsx
‚îÇ   ‚îî‚îÄ‚îÄ BNBUSDT.xlsx
‚îú‚îÄ‚îÄ notebooks/                     # Jupyter notebooks (optionnels pour visualisation)
‚îÇ   ‚îî‚îÄ‚îÄ quick_viz.ipynb           # Visualisation rapide des r√©sultats
‚îú‚îÄ‚îÄ src/                           # Code source Python
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py            # Chargement et preprocessing des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ correlation_analysis.py   # Analyses de corr√©lations crois√©es avec tests stat
‚îÇ   ‚îú‚îÄ‚îÄ var_models.py             # Mod√®les VAR avec validation rigoureuse
‚îÇ   ‚îú‚îÄ‚îÄ granger_tests.py          # Tests de causalit√© de Granger
‚îÇ   ‚îú‚îÄ‚îÄ strategy_builder.py       # Construction de strat√©gies bas√©es sur corr√©lations
‚îÇ   ‚îú‚îÄ‚îÄ backtesting.py            # Backtesting avec walk-forward
‚îÇ   ‚îú‚îÄ‚îÄ kpi_calculator.py         # Calcul des KPIs avec IC
‚îÇ   ‚îú‚îÄ‚îÄ scientific_validation.py  # Tests de robustesse et validation
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                  # Fonctions utilitaires
‚îú‚îÄ‚îÄ scripts/                       # Scripts d'ex√©cution automatis√©s
‚îÇ   ‚îú‚îÄ‚îÄ run_phase1.py             # MASTER SCRIPT - Lance toute la Phase 1
‚îÇ   ‚îú‚îÄ‚îÄ run_phase2.py             # MASTER SCRIPT - Lance la Phase 2
‚îÇ   ‚îî‚îÄ‚îÄ config.py                 # Configuration centralis√©e
‚îú‚îÄ‚îÄ pine_script/                   # Code Pine Script pour TradingView
‚îÇ   ‚îî‚îÄ‚îÄ correlation_strategy.pine
‚îú‚îÄ‚îÄ results/                       # R√©sultats et visualisations
‚îÇ   ‚îú‚îÄ‚îÄ correlation_matrices/
‚îÇ   ‚îú‚îÄ‚îÄ lag_analysis/
‚îÇ   ‚îú‚îÄ‚îÄ var_results/
‚îÇ   ‚îú‚îÄ‚îÄ granger_tests/
‚îÇ   ‚îú‚îÄ‚îÄ backtest_results/
‚îÇ   ‚îú‚îÄ‚îÄ kpi_reports/
‚îÇ   ‚îú‚îÄ‚îÄ scientific_validation/
‚îÇ   ‚îî‚îÄ‚îÄ final_report.pdf
‚îú‚îÄ‚îÄ requirements.txt               # D√©pendances Python
‚îú‚îÄ‚îÄ README.md                      # Documentation du projet
‚îî‚îÄ‚îÄ METHODOLOGY.md                 # Documentation m√©thodologique scientifique
```

---

## üìö CONTEXTE MATH√âMATIQUE ET M√âTHODOLOGIES

### 1. Branche Math√©matique
**√âconom√©trie financi√®re** - S√©ries temporelles multivari√©es

### 2. M√©thodes √† Impl√©menter

#### A. Cross-Correlation Lagged (CCF)
- **But** : Identifier les d√©calages temporels entre paires
- **Impl√©mentation** : Calculer la corr√©lation de Pearson entre une s√©rie et une autre d√©cal√©e de k p√©riodes (lags)
- **Librairies** : `pandas`, `numpy`, `statsmodels.tsa.stattools.ccf`
- **Output attendu** : 
  - Matrices de corr√©lation pour diff√©rents lags (de -50 √† +50 p√©riodes)
  - Graphiques CCF pour chaque paire de cryptos
  - Identification des lags significatifs (corr√©lation > 0.7 ou < -0.7)

#### B. Mod√®les VAR (Vector AutoRegressive)
- **But** : Capturer les dynamiques multivari√©es et interd√©pendances
- **Impl√©mentation** : `statsmodels.tsa.api.VAR`
- **√âtapes** :
  1. Test de stationnarit√© (ADF test)
  2. Diff√©renciation si n√©cessaire
  3. S√©lection de l'ordre optimal (AIC, BIC)
  4. Estimation du mod√®le VAR
  5. Analyse des coefficients et IRF (Impulse Response Functions)
- **Output attendu** :
  - Ordre optimal du mod√®le
  - Coefficients significatifs
  - Pr√©visions √† court terme

#### C. Tests de Causalit√© de Granger
- **But** : D√©terminer si une s√©rie aide √† pr√©dire une autre
- **Impl√©mentation** : `statsmodels.tsa.stattools.grangercausalitytests`
- **Output attendu** :
  - Matrice de causalit√© (qui influence qui)
  - P-values pour diff√©rents lags
  - Graphe de causalit√© dirig√©

---

## üî¨ PHASE 1 : ANALYSE EN PYTHON

### Objectif
Trouver des patterns de corr√©lation exploitables commercialement

### √âtapes de D√©veloppement

#### 1. Data Loading & Preprocessing
```python
# Fichier: src/data_loader.py
# - Charger tous les fichiers Excel du dossier ./data/
# - Colonnes: time, open, high, low, close, CVD(Ouverture), CVD(Haut), CVD(Bas), CVD(Fermer)
# - V√©rifier l'int√©grit√© des donn√©es (NaN, outliers)
# - Synchroniser les timestamps entre toutes les paires
# 
# TRAITEMENT DES 4 COLONNES CVD:
# Option 1: Utiliser CVD(Fermer) comme r√©f√©rence principale (recommand√©)
# Option 2: Calculer la moyenne des 4 CVD pour lisser le signal
# Option 3: Calculer le delta intra-bougie: CVD(Fermer) - CVD(Ouverture)
# Option 4: Utiliser les 4 CVD s√©par√©ment pour capturer la dynamique intra-bougie
#
# Recommandation initiale: CVD(Fermer) + delta intra-bougie
#
# - Cr√©er un DataFrame multivari√© avec colonnes: 
#   [timestamp, BTC_close, BTC_cvd, BTC_cvd_delta, ETH_close, ETH_cvd, ETH_cvd_delta, ...]
# - Calculer les returns logarithmiques pour chaque paire
# - Normaliser les CVD (z-score) pour comparabilit√© entre paires
```

**Colonnes pr√©sentes dans les Excel** :
- time (timestamp)
- open
- high
- low
- close
- CVD (Ouverture) - CVD √† l'ouverture de la bougie
- CVD (Haut) - CVD au plus haut de la bougie
- CVD (Bas) - CVD au plus bas de la bougie
- CVD (Fermer) - CVD √† la fermeture de la bougie

**Note** : Les 4 colonnes CVD fournissent une granularit√© intra-bougie du volume delta

#### 2. Analyse Exploratoire
```python
# Fichier: notebooks/01_data_exploration.ipynb
# - Statistiques descriptives de chaque paire
# - Visualisation des prix et volumes
# - Analyse de la distribution des returns
# - D√©tection des p√©riodes de haute/basse volatilit√©
# - Corr√©lation simple (statique) entre toutes les paires
```

#### 3. Cross-Correlation Analysis
```python
# Fichier: src/correlation_analysis.py
# Pour chaque paire (i, j):
#   - Calculer CCF pour lags de -50 √† +50 heures
#   - Identifier les lags avec |corr√©lation| > seuil (0.6, 0.7, 0.8)
#   - Cr√©er des heatmaps de corr√©lation par lag
#   - Extraire les "leading pairs" (qui pr√©c√®dent les mouvements)
```

#### 4. VAR Modeling
```python
# Fichier: src/var_models.py
# - Test de stationnarit√© (Augmented Dickey-Fuller)
# - Diff√©renciation des s√©ries si n√©cessaire
# - S√©lection de l'ordre optimal (max_lags = 24h)
# - Estimation du mod√®le VAR
# - Analyse des r√©sidus
# - Forecast √† horizon 1h, 4h, 12h
```

#### 5. Granger Causality
```python
# Fichier: src/granger_tests.py
# - Matrice de causalit√© 6x6
# - Tests pour max_lag = 1, 4, 8, 12, 24 heures
# - Identifier les paires "causales" (p-value < 0.05)
# - Cr√©er un graphe de causalit√© NetworkX
```

#### 6. Strategy Development
```python
# Fichier: src/strategy_builder.py
# Bas√© sur les r√©sultats pr√©c√©dents:
# - Identifier les signaux de trading:
#   * Si paire A monte avec lag de 2h ‚Üí paire B devrait suivre
#   * Si causalit√© forte A‚ÜíB ‚Üí utiliser A comme signal pour B
#   * Si corr√©lation n√©gative forte ‚Üí strat√©gie de pairs trading
# - D√©finir les r√®gles d'entr√©e/sortie
# - Param√®tres: seuils de corr√©lation, horizons temporels, taille des positions
```

#### 7. Backtesting
```python
# Fichier: src/backtesting.py
# - Impl√©mentation vectoris√©e du backtesting
# - Walk-forward analysis
# - Gestion des frais de transaction (0.1% par trade)
# - Gestion du risque (stop-loss, take-profit)
# - Calcul des m√©triques de performance
```

#### 8. KPI Calculation
```python
# Fichier: src/kpi_calculator.py
# KPIs √† calculer (OBLIGATOIRES):

# === PERFORMANCE ABSOLUE ===
# - Total Return (%)
# - Annualized Return (%)
# - Profitabilit√© sur Capital Fictif (ex: 10,000 USDT de d√©part)
#   * Capital Final
#   * Profit Net en USDT
#   * ROI (%)

# === RATIOS DE PERFORMANCE ===
# - Sharpe Ratio
# - Sortino Ratio
# - Calmar Ratio
# - Return over Maximum Drawdown (RoMaD)

# === GESTION DU RISQUE ===
# - Maximum Drawdown (%)
# - Average Drawdown (%)
# - Drawdown Duration (nombre de p√©riodes)
# - Value at Risk (VaR) 95% et 99%

# === STATISTIQUES DES TRADES ===
# - Win Rate (%) - OBLIGATOIRE
# - Nombre total de trades
# - Nombre de trades gagnants
# - Nombre de trades perdants
# - Profit Factor (gains totaux / pertes totales)
# - Average Win / Average Loss
# - Ratio Win/Loss
# - Largest Win / Largest Loss
# - Average Trade Duration (en heures)
# - Expectancy par trade

# === FR√âQUENCE DE TRADING ===
# - Trades per jour/semaine/mois
# - Temps moyen entre deux trades

# === STABILIT√â ===
# - Correlation des returns de la strat√©gie avec chaque paire
# - Rolling Sharpe Ratio (fen√™tre de 30 jours)
# - Consistency Score (% de mois positifs)
```

### Crit√®res de Succ√®s Phase 1
Une strat√©gie est consid√©r√©e **profitable** si TOUS les crit√®res suivants sont atteints :

**Performance Absolue :**
- Rentabilit√© annualis√©e > 20%
- Profitabilit√© sur capital fictif (10,000 USDT) > 2,000 USDT net (20%+)

**Ratios de Risque/Rendement :**
- Sharpe Ratio > 1.5
- Sortino Ratio > 2.0
- Maximum Drawdown < 20%
- Calmar Ratio > 1.0

**Statistiques de Trading :**
- Win Rate > 55% (OBLIGATOIRE)
- Profit Factor > 1.5
- Average Trade > 0 apr√®s frais
- Expectancy positive

**Robustesse :**
- Performance coh√©rente en walk-forward (√©cart < 30% entre training et testing)
- Pas de p√©riode de drawdown > 30 jours
- Au moins 30+ trades sur la p√©riode d'analyse

Si UN SEUL crit√®re √©choue ‚Üí **NO-GO pour Phase 2**

---

## üé® PHASE 2 : IMPL√âMENTATION PINE SCRIPT

### D√©clenchement
Cette phase ne commence QUE si la Phase 1 d√©montre une strat√©gie profitable selon les crit√®res ci-dessus.

### Objectif
Cr√©er un indicateur/strat√©gie TradingView pour backtesting visuel et d√©ploiement potentiel.

### Structure Pine Script
```pine
// Fichier: pine_script/correlation_strategy.pine
//@version=5
strategy("Crypto Correlation Strategy", overlay=true)

// INPUTS
// - D√©finir les param√®tres de corr√©lation trouv√©s en Python
// - Lags optimaux
// - Seuils de corr√©lation
// - Param√®tres de gestion du risque

// DATA FETCHING
// - R√©cup√©rer les donn√©es des 6 paires via request.security()
// - Calculer les returns

// CORRELATION CALCULATION
// - Impl√©menter les calculs de corr√©lation lagged
// - Utiliser ta.correlation() avec des s√©ries d√©cal√©es

// SIGNAL GENERATION
// - Reproduire la logique de la strat√©gie Python
// - G√©n√©rer les signaux d'achat/vente

// STRATEGY LOGIC
// - Entry conditions
// - Exit conditions
// - Stop-loss / Take-profit

// VISUALIZATION
// - Afficher les signaux sur le graphique
// - Tables avec les m√©triques de performance
// - Indicateurs de corr√©lation en temps r√©el
```

### Limitations Pine Script √† Anticiper
- Pas de calcul matriciel complexe (simplifier les VAR)
- Limitation √† ~5000 barres de donn√©es
- Pas de multi-timeframe complexe
- Focus sur les signaux CCF et causalit√© simple

---

## üõ†Ô∏è STACK TECHNIQUE

### Python
**Librairies requises** (requirements.txt) :
```
pandas>=2.0.0
numpy>=1.24.0
scipy>=1.10.0
statsmodels>=0.14.0
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.14.0
openpyxl>=3.1.0  # Pour lire Excel
networkx>=3.1    # Pour graphes de causalit√©
jupyter>=1.0.0
scikit-learn>=1.2.0
```

### Environnement
- Python 3.10+
- Jupyter Notebook/Lab
- Git pour versioning

---

## üìã BONNES PRATIQUES DE D√âVELOPPEMENT

### Code Quality
1. **Documentation** : Docstrings pour toutes les fonctions
2. **Type Hints** : Utiliser les annotations de type Python
3. **Modularit√©** : Fonctions r√©utilisables et testables
4. **Logging** : Utiliser le module `logging` pour tracer les analyses
5. **Config** : Centraliser les param√®tres dans un fichier de config

### Gestion de Donn√©es
1. Sauvegarder les r√©sultats interm√©diaires (pickle, CSV)
2. Versionner les datasets avec hash MD5
3. Cr√©er des checkpoints pour les analyses longues

### Visualisations
1. Graphiques interactifs avec Plotly pour exploration
2. Graphiques statiques avec Matplotlib/Seaborn pour rapports
3. Sauvegarder toutes les figures importantes

### Performance
1. Utiliser des op√©rations vectoris√©es (NumPy/Pandas)
2. √âviter les boucles Python quand possible
3. Profiler le code avec `cProfile` si n√©cessaire

---

## üìä LIVRABLES ATTENDUS

### Phase 1 (Python)
1. **Notebooks d'analyse** : Exploration compl√®te des donn√©es
2. **Code source modulaire** : Biblioth√®que r√©utilisable
3. **Rapport de corr√©lations** : 
   - Matrices de corr√©lation par lag
   - Graphes CCF
   - R√©sultats VAR
   - Matrice de causalit√© Granger
4. **Documentation de strat√©gie** : Description d√©taill√©e de la logique
5. **R√©sultats de backtesting** :
   - Equity curve
   - Drawdown chart
   - Distribution des returns
   - KPIs complets
6. **Recommandation GO/NO-GO** pour Phase 2

### Phase 2 (Pine Script)
1. **Code Pine Script** : Indicateur/Strat√©gie fonctionnel
2. **Backtest TradingView** : R√©sultats visuels sur historique long
3. **Guide d'utilisation** : Comment param√©trer l'indicateur
4. **Comparaison Python vs Pine** : Validation de la concordance

---

## üöÄ WORKFLOW DE D√âVELOPPEMENT - SPRINT INTENSIF 2 JOURS

### üî¥ JOUR 1 : PHASE 1 - ANALYSE PYTHON (8h de travail)

**Heure 0-1 : Setup & Data Loading**
- [ ] Cr√©er la structure du projet compl√®te
- [ ] Installer toutes les d√©pendances
- [ ] D√©velopper `data_loader.py` : chargement automatis√© des 6 fichiers Excel
- [ ] Synchronisation des timestamps
- [ ] Calcul des returns logarithmiques
- [ ] Validation de l'int√©grit√© des donn√©es (NaN check)

**Heure 1-3 : Cross-Correlation Analysis (CCF)**
- [ ] Impl√©menter `correlation_analysis.py` avec calcul CCF automatis√©
- [ ] Calcul matriciel pour lags -50 √† +50 heures pour TOUTES les paires (15 combinaisons)
- [ ] G√©n√©ration automatique des heatmaps de corr√©lation
- [ ] Extraction automatique des lags significatifs (|corr| > 0.7)
- [ ] Export des r√©sultats en CSV et PNG

**Heure 3-5 : Mod√®les VAR & Tests de Granger**
- [ ] `var_models.py` : Tests ADF de stationnarit√© sur toutes les s√©ries
- [ ] Diff√©renciation automatique si n√©cessaire
- [ ] Estimation VAR avec s√©lection automatique d'ordre (AIC/BIC)
- [ ] `granger_tests.py` : Matrice compl√®te de causalit√© 6x6
- [ ] Tests pour lags 1, 4, 8, 12, 24h
- [ ] G√©n√©ration du graphe de causalit√© NetworkX
- [ ] Export des p-values et r√©sultats significatifs

**Heure 5-7 : D√©veloppement & Backtesting de Strat√©gie**
- [ ] `strategy_builder.py` : D√©veloppement de 3-5 strat√©gies candidates bas√©es sur :
  - Signaux de lead-lag des CCF
  - Relations de causalit√© Granger
  - Combinaisons multi-paires
- [ ] `backtesting.py` : Engine de backtesting vectoris√© ultra-rapide
- [ ] Test des strat√©gies sur la p√©riode compl√®te
- [ ] Walk-forward validation (70% training, 30% testing)
- [ ] Int√©gration des frais de transaction (0.1% par trade)

**Heure 7-8 : KPIs, Validation & D√©cision GO/NO-GO**
- [ ] `kpi_calculator.py` : Calcul automatis√© de TOUS les KPIs
- [ ] G√©n√©ration des graphiques de performance (equity curve, drawdown)
- [ ] Rapport automatique de d√©cision GO/NO-GO
- [ ] Export complet des r√©sultats
- [ ] **D√âCISION FINALE** : Si crit√®res atteints ‚Üí Phase 2, sinon STOP

---

### üü¢ JOUR 2 : PHASE 2 - PINE SCRIPT (6-8h de travail)

**Uniquement si Phase 1 = GO**

**Heure 0-2 : Traduction Strat√©gie ‚Üí Pine Script**
- [ ] Analyser la strat√©gie retenue
- [ ] Simplifier les calculs pour Pine Script
- [ ] Coder la structure de base de l'indicateur
- [ ] Impl√©menter les calculs de corr√©lation lagged

**Heure 2-4 : Logique de Trading & Signaux**
- [ ] Coder les conditions d'entr√©e/sortie
- [ ] Impl√©menter stop-loss / take-profit
- [ ] Ajouter la gestion de position
- [ ] Tests unitaires sur donn√©es historiques

**Heure 4-6 : Backtesting TradingView & Optimisation**
- [ ] D√©ployer sur TradingView
- [ ] Backtesting sur historique long (6-12 mois si possible)
- [ ] Ajustement des param√®tres visuels
- [ ] Comparaison des r√©sultats avec Python

**Heure 6-8 : Validation & Documentation**
- [ ] V√©rification de la concordance Python ‚Üî Pine
- [ ] Documentation de l'indicateur
- [ ] Guide d'utilisation pour TradingView
- [ ] Rapport final complet

---

## ‚è±Ô∏è CONTRAINTES TEMPORELLES - AUTOMATISATION MAXIMALE

Pour tenir le d√©lai de 2 jours, le code doit √™tre :

1. **Enti√®rement automatis√©** : Z√©ro intervention manuelle entre les √©tapes
2. **Parall√©lis√©** : Utiliser `multiprocessing` pour calculs lourds
3. **Script d'ex√©cution master** : `run_phase1.py` et `run_phase2.py` qui lancent tout
4. **Minimal mais complet** : Pas de notebook exploratoire, code production direct
5. **R√©sultats auto-sauvegard√©s** : Chaque √©tape g√©n√®re et sauvegarde ses outputs

---

## ü§ñ SCRIPTS D'EX√âCUTION AUTOMATIS√âS

### Script Master Phase 1 : `scripts/run_phase1.py`

```python
"""
MASTER SCRIPT - PHASE 1
Lance automatiquement toute l'analyse en ~6-8h
"""

import logging
import time
from datetime import datetime
from pathlib import Path
import multiprocessing as mp

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'phase1_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

def main():
    """Ex√©cution s√©quentielle de toutes les √©tapes de Phase 1"""
    
    start_time = time.time()
    logger.info("="*80)
    logger.info("D√âBUT PHASE 1 - ANALYSE DE CORR√âLATIONS CRYPTO")
    logger.info("="*80)
    
    # ========== √âTAPE 1: CHARGEMENT DES DONN√âES ==========
    logger.info("\n[1/8] Chargement et pr√©paration des donn√©es...")
    from src.data_loader import load_and_prepare_data
    data, metadata = load_and_prepare_data('./data/')
    logger.info(f"‚úì Donn√©es charg√©es: {len(data)} observations, {len(data.columns)} colonnes")
    logger.info(f"‚úì P√©riode: {data.index[0]} ‚Üí {data.index[-1]}")
    
    # ========== √âTAPE 2: CORR√âLATIONS CROIS√âES ==========
    logger.info("\n[2/8] Analyse des corr√©lations crois√©es (CCF)...")
    from src.correlation_analysis import run_ccf_analysis
    ccf_results = run_ccf_analysis(data, max_lag=50, n_jobs=-1)
    logger.info(f"‚úì {ccf_results['n_significant']} corr√©lations significatives trouv√©es")
    logger.info(f"‚úì Seuil alpha ajust√©: {ccf_results['alpha_corrected']:.2e}")
    
    # ========== √âTAPE 3: TESTS DE STATIONNARIT√â ==========
    logger.info("\n[3/8] Tests de stationnarit√© (ADF)...")
    from src.var_models import test_all_stationarity
    stationarity_results = test_all_stationarity(data)
    logger.info(f"‚úì S√©ries stationnaires: {stationarity_results['n_stationary']}/{stationarity_results['n_total']}")
    
    # ========== √âTAPE 4: MOD√àLES VAR ==========
    logger.info("\n[4/8] Estimation des mod√®les VAR...")
    from src.var_models import estimate_var_strict
    var_results = estimate_var_strict(data, max_lags=24)
    logger.info(f"‚úì Ordre optimal VAR: {var_results['optimal_lag']}")
    logger.info(f"‚úì Mod√®le valide: {var_results['validation']['model_valid']}")
    
    # ========== √âTAPE 5: TESTS DE GRANGER ==========
    logger.info("\n[5/8] Tests de causalit√© de Granger...")
    from src.granger_tests import granger_causality_matrix_strict
    granger_results, alpha_corrected = granger_causality_matrix_strict(data, max_lag=12)
    n_causal = sum([1 for v in granger_results.values() 
                    for r in v.values() if r.get('is_causal', False)])
    logger.info(f"‚úì Relations causales significatives: {n_causal}")
    logger.info(f"‚úì Alpha corrig√©: {alpha_corrected:.2e}")
    
    # ========== √âTAPE 6: D√âVELOPPEMENT STRAT√âGIES ==========
    logger.info("\n[6/8] D√©veloppement des strat√©gies de trading...")
    from src.strategy_builder import build_strategies
    strategies = build_strategies(
        data=data,
        ccf_results=ccf_results,
        granger_results=granger_results,
        var_results=var_results
    )
    logger.info(f"‚úì {len(strategies)} strat√©gies candidates g√©n√©r√©es")
    
    # ========== √âTAPE 7: BACKTESTING ==========
    logger.info("\n[7/8] Backtesting des strat√©gies...")
    from src.backtesting import backtest_strategies
    backtest_results = backtest_strategies(
        strategies=strategies,
        data=data,
        initial_capital=10000,
        transaction_cost=0.001,
        walk_forward=True
    )
    logger.info(f"‚úì Strat√©gies test√©es avec walk-forward validation")
    
    # ========== √âTAPE 8: CALCUL DES KPIs ==========
    logger.info("\n[8/8] Calcul des KPIs et validation scientifique...")
    from src.kpi_calculator import calculate_all_kpis
    from src.scientific_validation import validate_strategy
    
    best_strategy = None
    best_sharpe = -float('inf')
    
    for strategy_name, bt_result in backtest_results.items():
        kpis = calculate_all_kpis(
            returns=bt_result['returns'],
            trades=bt_result['trades'],
            initial_capital=10000
        )
        
        validation = validate_strategy(
            strategy=strategy_name,
            backtest_result=bt_result,
            kpis=kpis,
            data=data
        )
        
        logger.info(f"\n--- {strategy_name} ---")
        logger.info(f"Sharpe Ratio: {kpis['sharpe_ratio']:.2f}")
        logger.info(f"Win Rate: {kpis['win_rate']:.1f}%")
        logger.info(f"Max Drawdown: {kpis['max_drawdown']:.1f}%")
        logger.info(f"Total Return: {kpis['total_return']:.1f}%")
        logger.info(f"Capital Final: ${kpis['final_capital']:,.2f}")
        logger.info(f"Validation: {'PASS ‚úì' if validation['passed'] else 'FAIL ‚úó'}")
        
        if validation['passed'] and kpis['sharpe_ratio'] > best_sharpe:
            best_strategy = strategy_name
            best_sharpe = kpis['sharpe_ratio']
    
    # ========== D√âCISION FINALE ==========
    logger.info("\n" + "="*80)
    logger.info("D√âCISION FINALE PHASE 1")
    logger.info("="*80)
    
    if best_strategy:
        logger.info(f"‚úì STRAT√âGIE PROFITABLE TROUV√âE: {best_strategy}")
        logger.info(f"‚úì Sharpe Ratio: {best_sharpe:.2f}")
        logger.info("\n>>> GO POUR PHASE 2 - PINE SCRIPT <<<")
        decision = "GO"
    else:
        logger.info("‚úó AUCUNE STRAT√âGIE NE SATISFAIT LES CRIT√àRES")
        logger.info("\n>>> NO-GO - ARR√äT DU PROJET <<<")
        decision = "NO-GO"
    
    # Sauvegarde des r√©sultats
    logger.info("\nSauvegarde des r√©sultats...")
    from src.utils import save_results
    save_results({
        'data_metadata': metadata,
        'ccf_results': ccf_results,
        'stationarity_results': stationarity_results,
        'var_results': var_results,
        'granger_results': granger_results,
        'backtest_results': backtest_results,
        'decision': decision,
        'best_strategy': best_strategy
    }, output_dir='./results/')
    
    elapsed = time.time() - start_time
    logger.info(f"\n‚úì Phase 1 termin√©e en {elapsed/3600:.2f}h")
    logger.info("="*80)
    
    return decision, best_strategy

if __name__ == "__main__":
    decision, best_strategy = main()
```

### Script Master Phase 2 : `scripts/run_phase2.py`

```python
"""
MASTER SCRIPT - PHASE 2
G√©n√©ration du code Pine Script et validation TradingView
Ne s'ex√©cute QUE si Phase 1 = GO
"""

import logging
import json
from pathlib import Path

logger = logging.getLogger(__name__)

def main():
    """Ex√©cution Phase 2 - Pine Script"""
    
    # V√©rifier la d√©cision de Phase 1
    results_file = Path('./results/phase1_results.json')
    if not results_file.exists():
        logger.error("Phase 1 non compl√©t√©e. Ex√©cutez run_phase1.py d'abord.")
        return
    
    with open(results_file, 'r') as f:
        phase1_results = json.load(f)
    
    if phase1_results['decision'] != 'GO':
        logger.error("Phase 1 = NO-GO. Phase 2 annul√©e.")
        return
    
    logger.info("="*80)
    logger.info("D√âBUT PHASE 2 - PINE SCRIPT")
    logger.info("="*80)
    
    best_strategy = phase1_results['best_strategy']
    logger.info(f"Strat√©gie √† impl√©menter: {best_strategy}")
    
    # ========== √âTAPE 1: G√âN√âRATION PINE SCRIPT ==========
    logger.info("\n[1/4] G√©n√©ration du code Pine Script...")
    from src.pine_generator import generate_pine_script
    pine_code = generate_pine_script(
        strategy_name=best_strategy,
        phase1_results=phase1_results
    )
    
    pine_file = Path('./pine_script/correlation_strategy.pine')
    pine_file.write_text(pine_code)
    logger.info(f"‚úì Code Pine Script g√©n√©r√©: {pine_file}")
    
    # ========== √âTAPE 2: INSTRUCTIONS TRADINGVIEW ==========
    logger.info("\n[2/4] G√©n√©ration des instructions TradingView...")
    instructions = f"""
    INSTRUCTIONS POUR TRADINGVIEW:
    
    1. Ouvrir TradingView
    2. Cr√©er un nouvel indicateur Pine Script
    3. Copier-coller le contenu de: {pine_file}
    4. Sauvegarder l'indicateur
    5. Appliquer sur le graphique BTCUSDT 1H
    6. Lancer le backtesting Strategy Tester
    7. V√©rifier les r√©sultats sur 6-12 mois
    
    Param√®tres recommand√©s:
    {json.dumps(phase1_results['best_strategy_params'], indent=2)}
    
    KPIs attendus (Python):
    - Sharpe Ratio: {phase1_results['best_kpis']['sharpe_ratio']:.2f}
    - Win Rate: {phase1_results['best_kpis']['win_rate']:.1f}%
    - Max DD: {phase1_results['best_kpis']['max_drawdown']:.1f}%
    """
    
    Path('./pine_script/INSTRUCTIONS.txt').write_text(instructions)
    logger.info("‚úì Instructions sauvegard√©es")
    
    # ========== √âTAPE 3: COMPARAISON ==========
    logger.info("\n[3/4] Pr√©parer la comparaison Python vs Pine...")
    logger.info("‚Üí Copier les r√©sultats TradingView manuellement")
    logger.info("‚Üí Utiliser src/pine_validator.py pour comparer")
    
    # ========== √âTAPE 4: DOCUMENTATION FINALE ==========
    logger.info("\n[4/4] G√©n√©ration de la documentation finale...")
    from src.utils import generate_final_report
    generate_final_report(phase1_results, pine_file)
    logger.info("‚úì Rapport final g√©n√©r√©: ./results/final_report.pdf")
    
    logger.info("\n" + "="*80)
    logger.info("PHASE 2 TERMIN√âE")
    logger.info("="*80)
    logger.info("\nPROCHAINES √âTAPES:")
    logger.info("1. Tester le code Pine sur TradingView")
    logger.info("2. Comparer les r√©sultats avec Python")
    logger.info("3. Ajuster si n√©cessaire")
    logger.info("4. D√©ployer si valid√©")

if __name__ == "__main__":
    main()
```

---

## üì¶ CONFIGURATION CENTRALIS√âE

### Fichier `scripts/config.py`

```python
"""
Configuration centralis√©e du projet
"""

from pathlib import Path

# Chemins
PROJECT_ROOT = Path(__file__).parent.parent
DATA_DIR = PROJECT_ROOT / 'data'
RESULTS_DIR = PROJECT_ROOT / 'results'
SRC_DIR = PROJECT_ROOT / 'src'

# Paires de cryptos
PAIRS = ['BTCUSDT', 'ETHUSDT', 'XRPUSDT', 'SOLUSDT', 'DOGEUSDT', 'BNBUSDT']

# Param√®tres d'analyse
MAX_LAG_CCF = 50  # Heures
MAX_LAG_VAR = 24  # Heures
MAX_LAG_GRANGER = 12  # Heures

# Param√®tres statistiques
ALPHA = 0.05  # Niveau de significativit√©
CONFIDENCE_LEVEL = 0.95

# Param√®tres de backtesting
INITIAL_CAPITAL = 10000  # USDT
TRANSACTION_COST = 0.001  # 0.1%
SLIPPAGE = 0.0005  # 0.05%

# Crit√®res de succ√®s (Phase 1)
CRITERIA = {
    'min_sharpe_ratio': 1.5,
    'min_sortino_ratio': 2.0,
    'max_drawdown': 0.20,  # 20%
    'min_win_rate': 0.55,  # 55%
    'min_profit_factor': 1.5,
    'min_annual_return': 0.20,  # 20%
    'min_calmar_ratio': 1.0,
    'min_trades': 30
}

# Param√®tres de validation
TRAIN_SIZE = 0.6
VAL_SIZE = 0.2
TEST_SIZE = 0.2

WALK_FORWARD_STEP = 24  # Heures
MIN_TEST_SIZE = 168  # 1 semaine

# Parall√©lisation
N_JOBS = -1  # Utiliser tous les CPU

# Random seed pour reproductibilit√©
RANDOM_SEED = 42
```

---

## üî¨ RIGUEUR M√âTHODOLOGIQUE SCIENTIFIQUE - PROTOCOLE STRICT

### ‚ö†Ô∏è R√àGLES NON-N√âGOCIABLES

Cette section d√©finit les **standards scientifiques stricts** √† respecter pour garantir la validit√© statistique des analyses. **AUCUN raccourci n'est acceptable.**

---

### 1. Tests de Significativit√© Statistique

#### A. Corr√©lations (CCF)
```python
# Pour CHAQUE corr√©lation calcul√©e:
# 1. Calculer la p-value associ√©e
# 2. Appliquer la correction de Bonferroni pour tests multiples:
#    Œ±_adjusted = Œ± / n_tests
#    Exemple: Œ± = 0.05, avec 15 paires √ó 101 lags = 1515 tests
#    ‚Üí Œ±_adjusted = 0.05 / 1515 = 0.000033
# 3. NE RETENIR que les corr√©lations avec p-value < Œ±_adjusted
# 4. Calculer les intervalles de confiance √† 95%

from scipy.stats import pearsonr

def calculate_ccf_with_significance(series1, series2, max_lag=50):
    """
    Calcule CCF avec tests de significativit√© rigoureux
    """
    results = []
    for lag in range(-max_lag, max_lag + 1):
        if lag < 0:
            s1 = series1[:lag]
            s2 = series2[-lag:]
        elif lag > 0:
            s1 = series1[lag:]
            s2 = series2[:-lag]
        else:
            s1 = series1
            s2 = series2
        
        corr, p_value = pearsonr(s1, s2)
        results.append({
            'lag': lag,
            'correlation': corr,
            'p_value': p_value,
            'n_obs': len(s1)
        })
    
    # Correction de Bonferroni
    n_tests = len(results) * 15  # 15 paires de cryptos
    alpha_corrected = 0.05 / n_tests
    
    # Filtrer les r√©sultats significatifs
    significant = [r for r in results if r['p_value'] < alpha_corrected]
    
    return results, significant, alpha_corrected
```

**Obligation** : Documenter dans les r√©sultats :
- Nombre de tests effectu√©s
- Seuil de significativit√© ajust√©
- Nombre de corr√©lations significatives vs totales
- Taux de faux positifs attendu

---

#### B. Tests de Stationnarit√© (Augmented Dickey-Fuller)
```python
from statsmodels.tsa.stattools import adfuller

def test_stationarity_strict(series, alpha=0.05):
    """
    Test ADF strict avec interpr√©tation rigoureuse
    """
    result = adfuller(series, autolag='AIC')
    
    is_stationary = result[1] < alpha  # p-value < 0.05
    
    output = {
        'adf_statistic': result[0],
        'p_value': result[1],
        'critical_values': result[4],
        'is_stationary': is_stationary,
        'lags_used': result[2],
        'n_obs': result[3]
    }
    
    # OBLIGATION: Si non-stationnaire, diff√©rencier
    if not is_stationary:
        series_diff = series.diff().dropna()
        # Re-tester la s√©rie diff√©renci√©e
        result_diff = adfuller(series_diff, autolag='AIC')
        output['diff_needed'] = True
        output['diff_p_value'] = result_diff[1]
        output['diff_is_stationary'] = result_diff[1] < alpha
    
    return output

# R√àGLE: Toutes les s√©ries doivent √™tre stationnaires avant VAR
# Si 2 diff√©renciations ne suffisent pas ‚Üí ABANDON de cette s√©rie
```

**Obligation** : 
- Tester TOUTES les s√©ries (prix ET CVD)
- Rapporter les p-values
- Ne JAMAIS utiliser de s√©ries non-stationnaires dans VAR

---

#### C. Mod√®les VAR - S√©lection Rigoureuse

```python
from statsmodels.tsa.api import VAR

def estimate_var_strict(data, max_lags=24):
    """
    Estimation VAR avec validation rigoureuse
    """
    model = VAR(data)
    
    # 1. S√©lection de l'ordre par crit√®res d'information
    lag_order_results = model.select_order(maxlags=max_lags)
    
    # Utiliser le consensus des crit√®res (AIC, BIC, HQIC)
    selected_lags = {
        'aic': lag_order_results.aic,
        'bic': lag_order_results.bic,
        'hqic': lag_order_results.hqic
    }
    
    # R√àGLE: Privil√©gier BIC (plus conservateur)
    optimal_lag = selected_lags['bic']
    
    # 2. Estimation du mod√®le
    fitted_model = model.fit(optimal_lag)
    
    # 3. VALIDATION DES R√âSIDUS (OBLIGATOIRE)
    residuals = fitted_model.resid
    
    # Test de normalit√© des r√©sidus (Jarque-Bera)
    from scipy.stats import jarque_bera
    normality_tests = {}
    for col in residuals.columns:
        jb_stat, jb_pval = jarque_bera(residuals[col])
        normality_tests[col] = {
            'statistic': jb_stat,
            'p_value': jb_pval,
            'is_normal': jb_pval > 0.05
        }
    
    # Test d'autocorr√©lation des r√©sidus (Ljung-Box)
    from statsmodels.stats.diagnostic import acorr_ljungbox
    autocorr_tests = {}
    for col in residuals.columns:
        lb_result = acorr_ljungbox(residuals[col], lags=10, return_df=True)
        autocorr_tests[col] = {
            'p_values': lb_result['lb_pvalue'].tolist(),
            'no_autocorr': all(lb_result['lb_pvalue'] > 0.05)
        }
    
    # Test d'h√©t√©rosc√©dasticit√© (White test)
    # ... (implementation d√©taill√©e)
    
    validation = {
        'lag_selection': selected_lags,
        'optimal_lag': optimal_lag,
        'normality': normality_tests,
        'autocorrelation': autocorr_tests,
        'model_valid': all([
            # Tous les r√©sidus doivent √™tre non-autocorr√©l√©s
            all([v['no_autocorr'] for v in autocorr_tests.values()])
        ])
    }
    
    return fitted_model, validation

# R√àGLE CRITIQUE: Si validation √©choue ‚Üí le mod√®le VAR n'est PAS fiable
# Ne PAS utiliser les r√©sultats d'un mod√®le VAR invalide
```

**Obligations** :
- Toujours valider les r√©sidus
- Rapporter les r√©sultats des tests
- Ne jamais utiliser un mod√®le dont les r√©sidus sont autocorr√©l√©s
- Documenter les limites du mod√®le

---

#### D. Tests de Causalit√© de Granger - Rigueur Maximale

```python
from statsmodels.tsa.stattools import grangercausalitytests

def granger_causality_matrix_strict(data, max_lag=12, alpha=0.05):
    """
    Matrice de causalit√© avec correction pour tests multiples
    """
    variables = data.columns
    n_vars = len(variables)
    n_tests = n_vars * (n_vars - 1)  # Chaque paire dans les 2 sens
    
    # Correction de Bonferroni
    alpha_corrected = alpha / n_tests
    
    causality_matrix = {}
    
    for caused in variables:
        causality_matrix[caused] = {}
        for causing in variables:
            if caused == causing:
                continue
            
            # Test de Granger : causing ‚Üí caused
            test_data = data[[caused, causing]]
            
            try:
                test_result = grangercausalitytests(
                    test_data, 
                    maxlag=max_lag, 
                    verbose=False
                )
                
                # Extraire les p-values pour chaque lag
                p_values = {}
                for lag in range(1, max_lag + 1):
                    # Utiliser le test F
                    p_values[lag] = test_result[lag][0]['ssr_ftest'][1]
                
                # D√©terminer le lag optimal (plus petite p-value)
                best_lag = min(p_values, key=p_values.get)
                best_p_value = p_values[best_lag]
                
                causality_matrix[caused][causing] = {
                    'p_values': p_values,
                    'best_lag': best_lag,
                    'best_p_value': best_p_value,
                    'is_causal': best_p_value < alpha_corrected,
                    'alpha_corrected': alpha_corrected
                }
                
            except Exception as e:
                causality_matrix[caused][causing] = {
                    'error': str(e),
                    'is_causal': False
                }
    
    return causality_matrix, alpha_corrected

# R√àGLE: NE RETENIR que les causalit√©s avec p-value < Œ±_corrected
# Documenter le nombre de tests et le seuil ajust√©
```

**Obligations** :
- Correction pour tests multiples (Bonferroni ou FDR)
- Tester plusieurs lags et rapporter le lag optimal
- Ne jamais affirmer une causalit√© si p-value > Œ±_corrected
- Distinguer "causalit√© statistique" et "causalit√© √©conomique"

---

### 2. Validation Crois√©e et Robustesse

#### A. Walk-Forward Analysis (OBLIGATOIRE)
```python
def walk_forward_validation(data, strategy_func, 
                            train_size=0.7, 
                            step_size=24,  # 1 jour
                            min_test_size=168):  # 1 semaine
    """
    Walk-forward analysis pour √©viter l'overfitting
    """
    results = []
    n = len(data)
    train_end = int(n * train_size)
    
    while train_end + min_test_size <= n:
        # P√©riode d'entra√Ænement
        train_data = data[:train_end]
        
        # P√©riode de test
        test_start = train_end
        test_end = min(test_start + min_test_size, n)
        test_data = data[test_start:test_end]
        
        # Entra√Æner la strat√©gie
        strategy = strategy_func(train_data)
        
        # Tester sur donn√©es out-of-sample
        test_performance = strategy.backtest(test_data)
        
        results.append({
            'train_start': 0,
            'train_end': train_end,
            'test_start': test_start,
            'test_end': test_end,
            'performance': test_performance
        })
        
        # Avancer la fen√™tre
        train_end += step_size
    
    return results

# R√àGLE: La strat√©gie doit performer de mani√®re STABLE sur tous les walks
# Si √©cart-type de performance > 50% ‚Üí strat√©gie INSTABLE ‚Üí REJET
```

#### B. Bootstrapping pour Intervalles de Confiance
```python
from scipy.stats import bootstrap

def bootstrap_confidence_intervals(returns, n_bootstrap=10000):
    """
    Calcul des IC √† 95% pour les m√©triques de performance
    """
    rng = np.random.RandomState(42)
    
    def sharpe(data):
        return np.mean(data) / np.std(data) * np.sqrt(252 * 24)  # Annualis√©
    
    result = bootstrap(
        (returns,), 
        sharpe, 
        n_resamples=n_bootstrap,
        random_state=rng
    )
    
    ci_low = result.confidence_interval.low
    ci_high = result.confidence_interval.high
    
    return ci_low, ci_high

# R√àGLE: Toujours rapporter les IC, pas seulement les moyennes
```

---

### 3. Gestion du Data Snooping et Overfitting

#### A. Hold-Out Set STRICT
```python
# R√àGLE ABSOLUE:
# 1. Diviser les donn√©es en 3:
#    - Training: 60% (pour d√©velopper la strat√©gie)
#    - Validation: 20% (pour ajuster les param√®tres)
#    - Test: 20% (NE JAMAIS TOUCHER jusqu'√† la fin)
#
# 2. Le test set ne doit JAMAIS influencer les d√©cisions
# 3. Les r√©sultats finaux sont ceux du test set UNIQUEMENT

def create_strict_data_splits(data):
    n = len(data)
    train_end = int(n * 0.6)
    val_end = int(n * 0.8)
    
    return {
        'train': data[:train_end],
        'validation': data[train_end:val_end],
        'test': data[val_end:]  # SACRED - DO NOT TOUCH
    }
```

#### B. Limite sur l'Optimisation de Param√®tres
```python
# R√àGLE: Maximum 5 param√®tres √† optimiser
# Plus de param√®tres = plus de risque d'overfitting

# R√àGLE: Grid search limit√©
# Pas plus de 10 valeurs par param√®tre
# Total de combinaisons: < 10,000

# R√àGLE: Penalty pour complexit√©
# Utiliser AIC/BIC pour p√©naliser les mod√®les complexes
```

---

### 4. Tests de Robustesse POST-D√©veloppement

Avant de valider la strat√©gie finale, effectuer:

#### A. Sensitivity Analysis
```python
# Tester la strat√©gie avec:
# - Param√®tres +/- 10%
# - Param√®tres +/- 20%
# 
# Si performance s'effondre avec petit changement ‚Üí strat√©gie FRAGILE ‚Üí REJET
```

#### B. Monte Carlo Simulation
```python
# 1000 simulations avec:
# - Ordre des trades al√©atoire
# - Dates de d√©part al√©atoires
# - Bootstrapping des returns
#
# Calculer la distribution de la performance
# Si P(Sharpe < 1.0) > 25% ‚Üí strat√©gie PAS ROBUSTE
```

#### C. R√©gime de March√©
```python
# Tester s√©par√©ment sur:
# - P√©riodes haussi√®res (Bull)
# - P√©riodes baissi√®res (Bear)
# - P√©riodes lat√©rales (Sideways)
#
# La strat√©gie doit √™tre profitable dans AU MOINS 2 r√©gimes sur 3
```

---

### 5. Documentation et Reproductibilit√©

#### Obligations Finales:

1. **Code Versionn√©** : Git avec commits atomiques
2. **Seed Fixe** : `np.random.seed(42)` partout
3. **Requirements.txt** : Versions exactes des librairies
4. **Rapport M√©thodologique** : Document s√©par√© d√©taillant:
   - Chaque test statistique effectu√©
   - Chaque hypoth√®se faite
   - Chaque limitation identifi√©e
   - Chaque d√©cision m√©thodologique justifi√©e
5. **R√©sultats Bruts** : Sauvegarder TOUS les r√©sultats interm√©diaires
6. **Checklist de Validation** : Cocher chaque √©tape m√©thodologique

---

## üö® CHECKLIST DE VALIDATION SCIENTIFIQUE

Avant de passer en Phase 2, V√âRIFIER:

- [ ] Toutes les corr√©lations ont √©t√© test√©es pour significativit√©
- [ ] Correction de Bonferroni appliqu√©e
- [ ] Tests de stationnarit√© effectu√©s sur toutes les s√©ries
- [ ] R√©sidus du VAR valid√©s (normalit√©, non-autocorr√©lation)
- [ ] Tests de Granger avec correction pour tests multiples
- [ ] Walk-forward validation effectu√©e (min 3 walks)
- [ ] Hold-out test set jamais touch√© pendant le d√©veloppement
- [ ] Intervalles de confiance calcul√©s pour tous les KPIs
- [ ] Tests de robustesse (sensitivity, Monte Carlo) pass√©s
- [ ] Performance stable sur diff√©rents r√©gimes de march√©
- [ ] Ratio signal/bruit > 2 (performance / √©cart-type)
- [ ] Pas de data snooping d√©tect√©
- [ ] Code reproductible √† 100% (seed fixe)
- [ ] Documentation m√©thodologique compl√®te
- [ ] Peer review du code et de la m√©thode (si possible)

**Si UN SEUL item √©choue ‚Üí STOP et correction avant Phase 2**

---

### Pi√®ges Statistiques
1. **Spurious Correlations** : V√©rifier que les corr√©lations ne sont pas dues au hasard
2. **Overfitting** : Ne pas sur-optimiser sur les donn√©es historiques
3. **Non-stationnarit√©** : Diff√©rencier les s√©ries si n√©cessaire
4. **Look-ahead bias** : Ne jamais utiliser de donn√©es futures dans les calculs

### R√©alisme du Trading
1. **Transaction Costs** : Toujours inclure les frais (0.1% par trade minimum)
2. **Slippage** : Consid√©rer 0.05-0.1% de slippage
3. **Market Impact** : Pour gros volumes, impact sur les prix
4. **Liquidit√©** : V√©rifier que les volumes permettent l'ex√©cution

### Validation Crois√©e
1. **Out-of-sample testing** : Garder 20-30% des donn√©es pour validation finale
2. **Walk-forward analysis** : Tester sur des p√©riodes roulantes
3. **Diff√©rents r√©gimes de march√©** : Bull, bear, sideways

---

## üéØ OBJECTIFS SMART DU PROJET

- **Sp√©cifique** : D√©velopper une strat√©gie de trading bas√©e sur les corr√©lations entre 6 paires crypto avec rigueur scientifique stricte
- **Mesurable** : Atteindre Sharpe > 1.5, Win Rate > 55%, DD < 20%, ROI > 20% sur capital fictif de 10,000 USDT
- **Atteignable** : Utiliser des m√©thodes √©prouv√©es d'√©conom√©trie avec validation statistique rigoureuse
- **R√©aliste** : Focus sur timeframe 1H et 3 mois de donn√©es (environ 2,160 observations)
- **Temporel** : 
  - **Jour 1 (8h)** : Phase 1 compl√®te - Analyse Python et d√©cision GO/NO-GO
  - **Jour 2 (6-8h)** : Phase 2 si GO - Pine Script et validation TradingView

**Contrainte critique** : Automatisation totale via scripts master pour respecter le timing serr√©

---

## üìû SUPPORT & RESSOURCES

### Documentation Cl√©s
- Statsmodels : https://www.statsmodels.org/stable/index.html
- Pine Script : https://www.tradingview.com/pine-script-docs/
- Pandas Time Series : https://pandas.pydata.org/docs/user_guide/timeseries.html

### R√©f√©rences Acad√©miques
- "Analysis of Financial Time Series" - Ruey S. Tsay
- "Time Series Analysis" - James D. Hamilton
- Articles sur cross-correlation dans le trading crypto

---

## ‚úÖ CHECKLIST DE VALIDATION FINALE

Avant de consid√©rer le projet termin√© :

- [ ] Toutes les analyses sont document√©es
- [ ] Le code est comment√© et test√©
- [ ] Les r√©sultats sont reproductibles
- [ ] Les KPIs sont calcul√©s correctement
- [ ] Le backtesting inclut les co√ªts r√©alistes
- [ ] La strat√©gie est valid√©e out-of-sample
- [ ] Le rapport final est r√©dig√©
- [ ] (Si Phase 2) Le Pine Script fonctionne sur TradingView
- [ ] (Si Phase 2) Les r√©sultats Python et Pine concordent

---

**Version** : 1.0  
**Derni√®re mise √† jour** : 31 octobre 2025  
**Status** : Pr√™t pour d√©veloppement